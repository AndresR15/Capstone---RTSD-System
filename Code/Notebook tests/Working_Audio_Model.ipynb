{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import wave\n",
    "import copy\n",
    "import mathj\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "# from keras.layers import LSTM, Input, Flatten, Merge, Bidirectional\n",
    "from keras.layers import LSTM, Input, Flatten, Bidirectional\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from Code.Misc.helper import *\n",
    "from Code.Misc.features import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LSTM Audio Only Model\n",
    "In this notebook we set up and test the audio only lstm model from the paper ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up global variable\n",
    "code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "data_path = code_path + \"/../data/\"\n",
    "sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n",
    "framerate = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For this model, we will predict over the emotions\n",
    "Anger,\n",
    "Excitement,\n",
    "Sadness\n",
    "\n",
    "We also predict for neutral emotions, meaning no strong emotion is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set up data\n",
    "We are using the IEMOCAP dataset, this includes:\n",
    "audio,\n",
    "transcription,\n",
    "motion capture,\n",
    "and video for a number of scripted and improvised scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-c5cfea624126>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpickle5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../Misc/Saved_data/data_collected.pickle\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mhandle\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mdata2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpickle5\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnpicklingError\u001B[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "# Load in data\n",
    "import pickle5\n",
    "with open(\"../Misc/Saved_data/data_collected.pickle\", 'rb') as handle:\n",
    "    data2 = pickle5.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature extraction\n",
    "These are a number of features that are extracted from the wav audio segments\n",
    "\n",
    "1. The temporal features (time domain features):\n",
    "\n",
    "* zero crossing rate\n",
    "* energy\n",
    "* entropy of energy\n",
    "\n",
    "2. The spectral features (frequency based features):\n",
    "* spectral centroid\n",
    "* spectral spread\n",
    "* spectral entropy\n",
    "* spectral flux\n",
    "* spectral rolloff\n",
    "\n",
    "3. 13 MFCC bands\n",
    "\n",
    "\n",
    "4. Chroma features (__Always seem to evaluate to 0__)\n",
    "* 13 Chroma\n",
    "* 12-dimensional chroma vector\n",
    "* standard deviation of chroma vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this method is used to extract features from the input wav\n",
    "# def calculate_features(frames, freq, options):\n",
    "#     window_sec = 0.1\n",
    "#     window_n = int(freq * window_sec)\n",
    "#\n",
    "#     st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "#\n",
    "#     if st_f.shape[1] > 2:\n",
    "#         i0 = 1\n",
    "#         i1 = st_f.shape[1] - 1\n",
    "#         if i1 - i0 < 1:\n",
    "#             i1 = i0 + 1\n",
    "#\n",
    "#         deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "#         for i in range(i0, i1):\n",
    "#             i_left = i - 1\n",
    "#             i_right = i + 1\n",
    "#             deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "#         return deriv_st_f\n",
    "#     elif st_f.shape[1] == 2:\n",
    "#         deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "#         deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "#         return deriv_st_f\n",
    "#     else:\n",
    "#         deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "#         deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "#         return deriv_st_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generating training data take a while, here we load the training data into the np array from a file\n",
    "x_train_file = \"Trained_models/x_test_speech.npy\"\n",
    "\n",
    "load = True\n",
    "\n",
    "if load:\n",
    "    with open(x_train_file, 'rb') as f:\n",
    "        x_train_speech = np.load(f)\n",
    "else:\n",
    "    # set up the training set\n",
    "    x_train_speech = []\n",
    "    \n",
    "    counter = 0\n",
    "    for ses_mod in data2:\n",
    "        x_head = ses_mod['signal']\n",
    "        st_features = calculate_features(x_head, framerate, None)\n",
    "        st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "        x_train_speech.append( st_features.T )\n",
    "\n",
    "    x_train_speech = np.array(x_train_speech)\n",
    "    x_train_speech.shape\n",
    "\n",
    "    # save model after it has been trained\n",
    "    with open(x_train_file, 'wb') as f:\n",
    "        np.save(f, x_train_speech)\n",
    "\n",
    "x_train_speech.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The LSTM Model\n",
    "\n",
    "The audio only model that is implemented here is a 2 layer LSTM model connected to a dense layer.\n",
    "\n",
    "A softmax function is used to get the confidence rating for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_model(optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(100, 34)))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = lstm_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split labels from training data\n",
    "Y_raw =[]\n",
    "for ses_mod in data2:\n",
    "    Y_raw  .append(ses_mod['emotion'])\n",
    "\n",
    "\n",
    "#converts labels into a one hot encoded version\n",
    "Y = label_binarize(Y_raw ,emotions_used)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training the model\n",
    "Training on about 5000 rows over 40 epochs takes about 80 minutes.\n",
    "To avoid retraining the model every time, we have exported the model into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save / load model from pickle file\n",
    "\n",
    "#model.save(\"Trained_models/2_layer_LSTM.pickle\")\n",
    "model = load_model(\"Trained_models/2_layer_LSTM.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "# hist = model.fit(x_train_speech, Y,\n",
    "#                  batch_size=100, nb_epoch=40, verbose=1, shuffle = True,\n",
    "#                  validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluating the Model\n",
    "This trained model has an accuracy of 54.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_train_speech[0:10], Y[0:10], batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict_result_file = \"Trained_models/predict_result.npy\"\n",
    "\n",
    "load = True\n",
    "\n",
    "if load:\n",
    "    with open(predict_result_file, 'rb') as f:\n",
    "        result = np.load(f)\n",
    "else:\n",
    "    result = model.predict(x_train_speech)\n",
    "    with open(predict_result_file, 'wb') as f:\n",
    "        np.save(f, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get prediction values for training data\n",
    "label = tf.argmax(result, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### We have to convert the encoded emotion labels back into a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# formatting the label data\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "col_y = []\n",
    "df_real = pd.DataFrame(Y_raw, columns = [\"emotion\"])\n",
    "for val in df_real[\"emotion\"].values:\n",
    "    x = 0\n",
    "    for c in range(0,len(cols)):\n",
    "        if cols[c] in val:\n",
    "            col_y.append(c)\n",
    "            break\n",
    "\n",
    "df_real[\"val\"] = col_y\n",
    "print(\"Actual Labels\")\n",
    "df_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# formatting the predicted data\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "col_y = []\n",
    "df_pred = pd.DataFrame(label, columns=[\"val\"])\n",
    "for x in df_pred[\"val\"].values:\n",
    "    col_y.append(cols[x])\n",
    "\n",
    "df_pred[\"emotion\"] = col_y\n",
    "print(\"Prediction Data\")\n",
    "df_pred.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looking into the distribution of the dataset, we can see a clear unbalance between neutral samples and samples that indicate a specific emotion.\n",
    "Although this may make the model more likely to guess that a sample is neutral, this is representative of real conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_raw).head()\n",
    "## Plot emotion histogram for input data\n",
    "plt.hist(Y_raw, bins=4, ec=\"black\")  # `density=False` would make counts\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title(\"Distribution of classes in input data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "plt.hist(df_pred[\"emotion\"], bins=4, ec=\"black\")\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title(\"Distribution of classes in prediction data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "emotions = ['ang', 'exc', 'neu', 'sad']\n",
    "## get avg between classes\n",
    "df_res = pd.DataFrame(result)\n",
    "df_label = pd.DataFrame(label)\n",
    "\n",
    "df_emotion_conf = pd.DataFrame()\n",
    "\n",
    "df_res.columns = emotions\n",
    "\n",
    "df_res[\"emo\"] = df_label[0]\n",
    "df_emotion_conf = df_res.groupby(['emo']).mean()\n",
    "df_emotion_conf[\"emo\"] = emotions\n",
    "df_emotion_conf = df_emotion_conf.set_index(\"emo\")\n",
    "\n",
    "\n",
    "plt.figure(figsize = (6, 5))\n",
    "sn.heatmap(df_emotion_conf, annot=True)\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Expected\")\n",
    "plt.title(\"Confusion matrix of mean confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading in new Wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "audio_path = \"F:/Capstone Project/IEMOCAP-Emotion-Detection/data/CMU_MOSI/Raw/Audio/WAV_11025/\"\n",
    "file_name = \"PZ-lDQFboO8.wav\"\n",
    "\n",
    "#ipd.Audio(audio_path + file_name) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "y, sr = librosa.load(audio_path + file_name, duration=10)\n",
    "fig, ax = plt.subplots()\n",
    "librosa.display.waveplot(y, sr=sr)\n",
    "ax.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = librosa.stft(y)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wav = get_audio(audio_path, file_name)\n",
    "(nchannels, sampwidth, framerate, nframes, comptype, compname), samples_wav = wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Splitting the Wav into samples\n",
    "after loading in a wav file to test on, we will be splitting it into a number of samples.\n",
    "Each sample will be a 3 second slice of the original wav (The slice length can be changed by changing the timeq).\n",
    "An overlap can also be used between samples, for this test we use a 1 second overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len_wav = nframes / framerate # length of wav in seconds\n",
    "\n",
    "timeq = 3 # length of sample slice in seconds\n",
    "overlap = 1 # overlap between samples\n",
    "\n",
    "left = samples_wav[0::nchannels]\n",
    "right = samples_wav[1::nchannels]\n",
    "\n",
    "samples = []\n",
    "for t_start in range(0, int(len_wav), int(timeq)):\n",
    "    if t_start > int(t_start):\n",
    "        t_start = t_start\n",
    "\n",
    "    if t_start == 0: #first sample\n",
    "        start = t_start\n",
    "        end = t_start + timeq\n",
    "    else:\n",
    "        start = t_start - overlap\n",
    "        end = t_start + timeq - overlap\n",
    "\n",
    "    if end > len_wav:\n",
    "        end = len_wav\n",
    "    sample_right = right[int(start * framerate):int(end * framerate)]\n",
    "    sample_left = left[int(start * framerate):int(end * framerate)]\n",
    "    # print(\"sample start: \" + str(start) + \" | sample end: \" + str(end))\n",
    "\n",
    "    #normalize data\n",
    "    norm = np.linalg.norm(sample_left)\n",
    "    normal_array = sample_left/norm\n",
    "\n",
    "    samples.append(normal_array) #, 'right': sample_right})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up the training set\n",
    "wav_in = []\n",
    "\n",
    "counter = 0\n",
    "for ses_mod in samples:\n",
    "    st_features = calculate_features(ses_mod, framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    wav_in.append( st_features.T )\n",
    "\n",
    "wav_in = np.array(wav_in)\n",
    "wav_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Predict on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "wav_test_results = model.predict(wav_in)\n",
    "print(\"time = \" + str(time.time() - t0))\n",
    "#wav_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wav_test_results_max = tf.argmax(wav_test_results, axis = 1)\n",
    "wav_test_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# formatting the predicted data\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "col_y = []\n",
    "df_pred_wav = pd.DataFrame(wav_test_results, columns=cols)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df_pred_wav['ang'], label=\"Anger\", color='r')\n",
    "plt.plot(df_pred_wav['exc'], label=\"Excited\", color='y')\n",
    "plt.plot(df_pred_wav['neu'], label=\"Neutral\", color='g')\n",
    "plt.plot(df_pred_wav['sad'], label=\"Sad\", color='b')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train_test = x_train_speech[0:101]\n",
    "y_test = Y[0:101]\n",
    "import time\n",
    "t0 = time.time()\n",
    "res = model.predict(x_train_test)\n",
    "print(\"time = \" + str(time.time() - t0))\n",
    "df = pd.DataFrame(res, columns=['ang', 'exc', 'neu', 'sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Real Time Audio Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib tk\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "df_pred_wav = pd.DataFrame(columns=cols)\n",
    "fig , ax = plt.subplots()\n",
    "ax.plot([0], label=\"Anger\", color='r')\n",
    "ax.plot([0], label=\"Excited\", color='y')\n",
    "ax.plot([0], label=\"Neutral\", color='g')\n",
    "ax.plot([0], label=\"Sad\", color='b')\n",
    "\n",
    "    \n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# x = np.arange(0, 50)\n",
    "# line, = ax.plot(x)\n",
    "\n",
    "\n",
    "graph_window = 10\n",
    "for ses_mod in samples:\n",
    "    #time.sleep(0.2)\n",
    "    # Extract Features\n",
    "    \n",
    "    wav_in = []\n",
    "    st_features = calculate_features(ses_mod, framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    wav_in.append( st_features.T )\n",
    "    wav_in = np.array(wav_in)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    wav_test_results = model.predict(wav_in)\n",
    "#     print(\"time = \" + str(time.time() - t0))\n",
    "    #print(\"prediction = \" + str(wav_test_results))\n",
    "    \n",
    "    df_pred_wav = df_pred_wav.append({cols[0]:wav_test_results[0][0],\n",
    "                        cols[1]:wav_test_results[0][1],\n",
    "                        cols[2]:wav_test_results[0][2],\n",
    "                        cols[3]:wav_test_results[0][3]\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    df_pred_wav_view = df_pred_wav[df_pred_wav.shape[0] - graph_window : ]\n",
    "    \n",
    "    #plt.cla()\n",
    "    \n",
    "    ax.axhline(y=0.5, color='r', linestyle='--')\n",
    "    ax.plot(df_pred_wav_view['ang'], label=\"Anger\", color='r')\n",
    "    ax.plot(df_pred_wav_view['exc'], label=\"Excited\", color='y')\n",
    "    ax.plot(df_pred_wav_view['neu'], label=\"Neutral\", color='g')\n",
    "    ax.plot(df_pred_wav_view['sad'], label=\"Sad\", color='b')\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "print(\"Finished\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type(ses_mod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}