{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "from Code.Misc.helper import *\n",
    "from Code.Misc.features import *\n",
    "from Code.Misc.models import audio_only_model, audio_text_model\n",
    "\n",
    "import pyaudio\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tkinter import TclError\n",
    "\n",
    "# use this backend to display in separate Tk window\n",
    "%matplotlib tk\n",
    "#%matplotlib inline\n",
    "\n",
    "# constants\n",
    "\n",
    "TIME_SEC = 0.5\n",
    "RATE = 16000                 # samples per second\n",
    "CHUNK = int(RATE * TIME_SEC) # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "DEVICE = 5\n",
    "\n",
    "# p = pyaudio.PyAudio()\n",
    "# for i in range(p.get_device_count()):\n",
    "#     print(p.get_device_info_by_index(i))\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],\n",
    "                                         enable=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def plot_line_graph(graph, data):\n",
    "    graph.axhline(y=0.5, color='r', linestyle='--')\n",
    "    #print(data.index)\n",
    "\n",
    "    ang_data = data['ang']\n",
    "    exc_data = data['exc']\n",
    "    neu_data = data['neu']\n",
    "    sad_data = data['sad']\n",
    "\n",
    "    graph.plot(ang_data, label=\"Anger\", color='r')\n",
    "    graph.plot(exc_data, label=\"Excited\", color='y')\n",
    "    graph.plot(neu_data, label=\"Neutral\", color='g')\n",
    "    graph.plot(sad_data, label=\"Sad\", color='b')\n",
    "    graph.legend(loc=\"upper left\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "def plot_bar_graph (graph, data):\n",
    "    graph.axhline(y=0.5, color='r', linestyle='--')\n",
    "    graph.bar(x=0, height=data[0], label=\"Anger\", color='r')\n",
    "    graph.bar(x=1, height=data[1], label=\"Excited\", color='y')\n",
    "    graph.bar(x=2, height=data[2], label=\"Neutral\", color='g')\n",
    "    graph.bar(x=3, height=data[3], label=\"Sad\", color='b')\n",
    "    graph.legend(loc=\"upper left\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "def plot_text(text_array, polarity):\n",
    "    char_size = 12\n",
    "    empty_string_size = char_size\n",
    "    total_input_string_size = 0\n",
    "\n",
    "    word_index = 0.012\n",
    "    text_total= \"\"\n",
    "\n",
    "    plt.cla()\n",
    "\n",
    "    plt.rcParams.update({'font.size': char_size})\n",
    "\n",
    "    if polarity > 0:\n",
    "        colour = \"green\"\n",
    "    elif polarity < 0:\n",
    "        colour = \"red\"\n",
    "    else:\n",
    "        colour = \"gray\"\n",
    "\n",
    "    for text in text_array:\n",
    "        text = text + \" \"\n",
    "        text_size = len(text) * 0.012\n",
    "        total_input_string_size += text_size\n",
    "\n",
    "        plt.text(word_index, 0.5, text, bbox=dict(facecolor=colour,\n",
    "                                                  alpha=0.5))\n",
    "        word_index += text_size\n",
    "\n",
    "    #plt.text(0.1, 0.5, text_total, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "    plt.xlim([0, word_index])\n",
    "\n",
    "    return plt\n",
    "\n",
    "def noise_filter(prev_val: pd.DataFrame, cur_val: pd.DataFrame, a = 0.8):\n",
    "\n",
    "    filtered_value = pd.DataFrame()\n",
    "    for col in prev_val.columns.values:\n",
    "        filtered_value[col] = [a * float(prev_val[col]) +\n",
    "                               (1-a) * float(cur_val[col])]\n",
    "\n",
    "    return filtered_value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting stram decleration\n"
     ]
    }
   ],
   "source": [
    "# pyaudio class instance\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "print(\"starting stram decleration\")\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    "    input_device_index = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# set up model\n",
    "\n",
    "use_old_model = False\n",
    "if use_old_model:\n",
    "    model = load_model(\"../Misc/Saved_data/Trained_models/2_layer_LSTM.pickle\")\n",
    "else:\n",
    "    model = keras.models.load_model('../Misc/Saved_data/Trained_models' +\n",
    "                                    '/Weights/Audio_only/model')\n",
    "\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "\n",
    "df_pred_wav = pd.DataFrame([np.zeros(4)], columns=cols)\n",
    "data_prev = []\n",
    "graph_window = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)\n",
    "fig , ax = plt.subplots(3)\n",
    "\n",
    "# basic formatting for the axes\n",
    "ax[0].set_title('Emotion Prediction')\n",
    "ax[0].set_xlabel('Time')\n",
    "ax[0].set_ylabel('Confidence')\n",
    "\n",
    "ax[0] = plot_line_graph(ax[0], df_pred_wav)\n",
    "\n",
    "# show the plot\n",
    "plt.show(block=False)\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_rate = 16000\n"
     ]
    }
   ],
   "source": [
    "import deepspeech as ds\n",
    "from textblob import TextBlob\n",
    "import scipy.signal as sps\n",
    "\n",
    "version_dir = \"F:\\Capstone Project\\Capstone---RTSD-System/Code\\Misc\\Saved_data\\Trained_models\\deep_speech_models/\"\n",
    "model_file_8 = version_dir + \"0.8.2/deepspeech-0.8.2-models.pbmm\"\n",
    "scorer_file_8 = version_dir + \"0.8.2/deepspeech-0.8.2-models.scorer\"\n",
    "\n",
    "deepspeech_model_8 = ds.Model(model_file_8)\n",
    "deepspeech_model_8.enableExternalScorer(scorer_file_8)\n",
    "\n",
    "print(\"Sample_rate = \" + str(deepspeech_model_8.sampleRate()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop\n",
      "trigger deepspeech\n",
      "each one hypothesis havana aguadiente reasoning basically the number here this is just eugenia shows my temples we\n",
      "trigger deepspeech\n",
      "once you know in there says he have i succeed this alsatian might be as a treatise what was just and the horse going to chase and he sent so i working niggards like ad with those before low damianus to be re\n",
      "trigger deepspeech\n",
      "manslaughter also didn't in the seminal behave to do mike fight on that if we can the teuton is the issue running into\n",
      "trigger deepspeech\n",
      "if the indelicate on in heaven don't remember is my debenham of much which is to be a full forty four one cares steam car must they wish i were getting condition the buff am riding of her\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-c326deca14f2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[1;31m# Generate features from data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m     \u001B[0mst_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcalculate_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_int\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mRATE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m     \u001B[0mst_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpad_sequence_into_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxlen\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Capstone Project\\Capstone---RTSD-System\\Code\\Misc\\helper.py\u001B[0m in \u001B[0;36mcalculate_features\u001B[1;34m(frames, freq, options)\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[0mwindow_n\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfreq\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mwindow_sec\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m     \u001B[0mst_f\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstFeatureExtraction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfreq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwindow_n\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwindow_n\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mst_f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Capstone Project\\Capstone---RTSD-System\\Code\\Misc\\features.py\u001B[0m in \u001B[0;36mstFeatureExtraction\u001B[1;34m(signal, Fs, Win, Step)\u001B[0m\n\u001B[0;32m    562\u001B[0m         \u001B[0mcurFV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstEnergy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m                           \u001B[1;31m# short-term energy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m         \u001B[0mcurFV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstEnergyEntropy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m                    \u001B[1;31m# short-term entropy of energy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 564\u001B[1;33m         \u001B[1;33m[\u001B[0m\u001B[0mcurFV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurFV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstSpectralCentroidAndSpread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFs\u001B[0m\u001B[1;33m)\u001B[0m    \u001B[1;31m# spectral centroid and spread\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    565\u001B[0m         \u001B[0mcurFV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstSpectralEntropy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m                  \u001B[1;31m# spectral entropy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    566\u001B[0m         \u001B[0mcurFV\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m6\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstSpectralFlux\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mXprev\u001B[0m\u001B[1;33m)\u001B[0m              \u001B[1;31m# spectral flux\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Capstone Project\\Capstone---RTSD-System\\Code\\Misc\\features.py\u001B[0m in \u001B[0;36mstSpectralCentroidAndSpread\u001B[1;34m(X, fs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mstSpectralCentroidAndSpread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     56\u001B[0m     \u001B[1;34m\"\"\"Computes spectral centroid of frame (given abs(FFT))\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 57\u001B[1;33m     \u001B[0mind\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfs\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2.0\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     58\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[0mXt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "import re\n",
    "\n",
    "WINDOW_SIZE = 0.5\n",
    "WINDOW_N = 20\n",
    "buffer = deque(maxlen=WINDOW_N)\n",
    "\n",
    "CHUNK = int(RATE * WINDOW_SIZE)\n",
    "\n",
    "#fill buffer\n",
    "for i in range(WINDOW_N):\n",
    "    buffer.append([])\n",
    "\n",
    "# set default text and sentiment\n",
    "text = \"\"\n",
    "sentiment = 0\n",
    "\n",
    "delay = 0\n",
    "\n",
    "buffer_fill = 0\n",
    "print(\"starting loop\")\n",
    "while (True):\n",
    "    time_collect = time.time()\n",
    "\n",
    "    # binary data\n",
    "    data_new = stream.read(CHUNK)\n",
    "\n",
    "    time_collect = time.time() - time_collect\n",
    "\n",
    "    predict_time_start = time.time()\n",
    "    #convert data to integers, make np array, then offset it by 127\n",
    "    # data_new = struct.unpack(str(2 * CHUNK) + 'B', data_new)\n",
    "    data_from_buffer = np.frombuffer(data_new, dtype=np.int16)\n",
    "\n",
    "    buffer.append(data_from_buffer)\n",
    "    buffer_fill += 1\n",
    "\n",
    "    # for i in range(len(buffer)):\n",
    "    #     data_prev = buffer[i]\n",
    "    #     data_int = np.append(data_int, data_prev)\n",
    "    data_int = []\n",
    "    for sample in buffer:\n",
    "        data_int += list(sample)\n",
    "\n",
    "    data_int = np.array(data_int).astype('int16')\n",
    "   #data_int = data_new\n",
    "    if buffer_fill >= WINDOW_N:\n",
    "        print(\"trigger deepspeech\")\n",
    "        stream_context = deepspeech_model_8.createStream()\n",
    "\n",
    "        wav_write(\"audio_export/______output.wav\",\n",
    "                  rate=16000, data=data_int)\n",
    "\n",
    "        # feed audio array to model\n",
    "        stream_context.feedAudioContent(data_int.astype('int16'))\n",
    "\n",
    "        # print output text\n",
    "        text = stream_context.finishStream()\n",
    "\n",
    "        print(text)\n",
    "        sentiment = TextBlob(text).polarity\n",
    "\n",
    "        text = re.sub(\"(.{64})\", \"\\\\1\\n\", text, 0, re.DOTALL)\n",
    "\n",
    "        buffer_fill = 0\n",
    "\n",
    "    # Generate features from data\n",
    "    st_features = calculate_features(data_int, RATE, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "\n",
    "    # reshape input from (34, 100) to (1, 100, 34)\n",
    "    st_features = np.array([st_features.T])\n",
    "\n",
    "    # predict on model\n",
    "    with tf.device('/gpu:0'):\n",
    "        wav_test_results = model.predict(st_features)\n",
    "\n",
    "    predict_time_total = time.time() - predict_time_start\n",
    "\n",
    "    graphing_time_start = time.time()\n",
    "\n",
    "    predicted_values = pd.DataFrame({cols[0]:wav_test_results[0][0],\n",
    "                                 cols[1]:wav_test_results[0][1],\n",
    "                                 cols[2]:wav_test_results[0][2],\n",
    "                                 cols[3]:wav_test_results[0][3]\n",
    "    }, index=[1])\n",
    "\n",
    "    # pass previous values to filter function\n",
    "    predicted_values = noise_filter(df_pred_wav.tail(1),\n",
    "                                    predicted_values)\n",
    "\n",
    "    df_pred_wav = df_pred_wav.append(predicted_values,\n",
    "                                     ignore_index=True)\n",
    "\n",
    "    df_pred_wav_view = df_pred_wav.tail(graph_window)\n",
    "    df_pred_wav_view.reset_index(drop=True, inplace=True)\n",
    "    ax[0].cla()\n",
    "    ax[1].cla()\n",
    "\n",
    "    ax[0] = plot_line_graph(ax[0], df_pred_wav_view)\n",
    "\n",
    "    last_res = wav_test_results[0]\n",
    "    ax[1] = plot_bar_graph (ax[1], last_res)\n",
    "\n",
    "    ax[2] = plot_text([text, str(buffer_fill)], sentiment)\n",
    "\n",
    "    graphing_time_total = time.time() - graphing_time_start\n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "\n",
    "    except TclError:\n",
    "\n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "\n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "        print('prediction_time = {f} seconds'.format(predict_time_total))\n",
    "\n",
    "    data_prev = data_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST = np.frombuffer(stream.read(CHUNK * 20), dtype=np.int16)\n",
    "wav_write(\"audio_export/______output_1.wav\", rate=16000, data=TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wav_write(\"audio_export/______output.wav\",\n",
    "          rate=16000, data=data_int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(data_int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}