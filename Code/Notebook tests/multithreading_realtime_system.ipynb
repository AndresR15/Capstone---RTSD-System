{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Program Files\\Ananconda\\envs\\Tersorflow-gpu\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from Code.Misc.helper import *\n",
    "\n",
    "import numpy as np\n",
    "from Code.Misc.split_segments import *\n",
    "import pyaudio\n",
    "import wave\n",
    "import errno\n",
    "import time\n",
    "import calendar\n",
    "import os\n",
    "import copy\n",
    "import concurrent.futures\n",
    "from collections import deque\n",
    "\n",
    "from tkinter import TclError\n",
    "import scipy.signal as sps\n",
    "import deepspeech as ds\n",
    "from textblob import TextBlob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from graph_formating import *\n",
    "\n",
    "from Code.Misc.models import audio_only_model, audio_text_model\n",
    "\n",
    "# use this backend to display in separate Tk window\n",
    "%matplotlib tk\n",
    "#%matplotlib inline\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean up environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Clean all old wave files\n",
    "rem_flag = False\n",
    "r = os.listdir('../../Data/Thread_files/')\n",
    "for i in r:\n",
    "    try:\n",
    "        if i.endswith('wav'):\n",
    "            rem_flag = True\n",
    "            os.remove(i)\n",
    "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
    "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
    "            pass\n",
    "print(rem_flag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Initialize pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Setup format info\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "DEVICE = 5\n",
    "RATE = 44100\n",
    "file_len = 5\n",
    "CHUNK = int(RATE / 2)\n",
    "\n",
    "# Create fast I/O buffer\n",
    "d = deque(maxlen=int(RATE / CHUNK * file_len))\n",
    "# p_name = int(calendar.timegm(time.gmtime()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Models\n",
    "\n",
    "### Custom Model Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# set up model\n",
    "multi_modal = True\n",
    "if multi_modal:\n",
    "    model = load_model('../Misc/Saved_data/Trained_models' +\n",
    "                                    '/Weights/Audio_Text/model')\n",
    "else:\n",
    "    model = load_model('../Misc/Saved_data/Trained_models' +\n",
    "                                    '/Weights/Audio_only/model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deepspeech model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_rate = 16000\n"
     ]
    }
   ],
   "source": [
    "version_dir = \"F:\\Capstone Project\\Capstone---RTSD-System/Code\\Misc\\Saved_data\\Trained_models\\deep_speech_models/\"\n",
    "model_file_8 = version_dir + \"0.8.2/deepspeech-0.8.2-models.pbmm\"\n",
    "scorer_file_8 = version_dir + \"0.8.2/deepspeech-0.8.2-models.scorer\"\n",
    "\n",
    "deepspeech_model_8 = ds.Model(model_file_8)\n",
    "deepspeech_model_8.enableExternalScorer(scorer_file_8)\n",
    "\n",
    "print(\"Sample_rate = \" + str(deepspeech_model_8.sampleRate()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "\n",
    "df_pred_wav = pd.DataFrame([np.zeros(4)], columns=cols)\n",
    "data_prev = []\n",
    "graph_window = 30\n",
    "\n",
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)\n",
    "fig , ax = plt.subplots(3)\n",
    "\n",
    "# basic formatting for the axes\n",
    "ax[0].set_title('Emotion Prediction')\n",
    "ax[0].set_xlabel('Time')\n",
    "ax[0].set_ylabel('Confidence')\n",
    "\n",
    "ax[0] = plot_line_graph(ax[0], df_pred_wav)\n",
    "\n",
    "# show the plot\n",
    "plt.show(block=False)\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Up Buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 0.5\n",
    "WINDOW_N = 10\n",
    "process_buffer = deque(maxlen=WINDOW_N)\n",
    "\n",
    "feeder_buffer =  deque() # create empty buffer for holding in file data\n",
    "\n",
    "#fill buffer\n",
    "for i in range(WINDOW_N):\n",
    "    process_buffer.append([])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up Passive Audio Capture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "idx = 0\n",
    "file_index = {}\n",
    "# Thread called file I/O function\n",
    "def write_to_file(arg):\n",
    "    global wf, idx, file_index\n",
    "\n",
    "    # Write 5s of audio to file\n",
    "    for elem in arg:\n",
    "        wf.writeframes(elem)\n",
    "\n",
    "    # If file is at the desired length close it, rename it to its utc start time (cant get ms?) and open the next temp\n",
    "    # file for writing to\n",
    "    if wf.tell() == RATE * file_len:\n",
    "        wf.close()\n",
    "        recording_name = str(calendar.timegm(time.gmtime()) - file_len) + '.wav'\n",
    "        os.rename('../../Data/Thread_files/temp.wav', '../../Data/Thread_files/'+ recording_name)\n",
    "        wf = wave.open('../../Data/Thread_files/temp.wav', 'wb')\n",
    "        wf.setnchannels(1)\n",
    "        wf.setframerate(RATE)\n",
    "        wf.setsampwidth(2)\n",
    "        return_set = (idx, recording_name)\n",
    "\n",
    "        # add to file index\n",
    "        file_index[idx] = recording_name\n",
    "\n",
    "        #print(\"idx = \" + str(idx))\n",
    "\n",
    "        idx += 1\n",
    "        return return_set\n",
    "\n",
    "# Pyaudio callback which appends HW audio buffer data to fast I/O 5s long buffer\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    if status != 0:\n",
    "        print (\"Non zero status\")\n",
    "        exit()\n",
    "    global d\n",
    "    d.append(in_data)\n",
    "\n",
    "    # If 5s worth of audio is collected, copy to secondary buffer and pass to thread function for file I/O, then\n",
    "    # clear 5s buffer\n",
    "    if len(d) == RATE / CHUNK * file_len:\n",
    "        frames = copy.copy(d)\n",
    "        thread_list.append(executor.submit(write_to_file, frames))\n",
    "        # thread = Thread(target=write_to_file, args=[frames])\n",
    "        # thread.start()\n",
    "        d.clear()\n",
    "        #print ('Copied 5s buffer: ')\n",
    "\n",
    "    return in_data, pyaudio.paContinue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# set up executer and buffer pool\n",
    "executor = concurrent.futures.ThreadPoolExecutor(max_workers=5)\n",
    "thread_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "audio_path = \"Code/Notebook tests/audio_export/\"\n",
    "audio_path = \"F:\\Capstone Project\\Capstone---RTSD-System\\Data\\CMU_MOSI\\Raw\\Audio\\WAV_16000\\Full/\"\n",
    "file_name = \"0h-zjBukYpk.wav\"\n",
    "\n",
    "if rem_flag:\n",
    "    # Open initial temp file and setup\n",
    "    wf = wave.open('../../Data/Thread_files/temp.wav', 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.setsampwidth(2)\n",
    "\n",
    "else:\n",
    "    wf = wave.open(audio_path + file_name, 'r')\n",
    "    split_wav = SplitWavAudio(audio_path,file_name)\n",
    "    split_wav.multiple_split(sec_per_split=5)\n",
    "\n",
    "#os.remove('../Misc/Saved_data/temp.wav')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Setup audio input stream\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK,\n",
    "                input_device_index=DEVICE,\n",
    "                stream_callback=callback)\n",
    "\n",
    "# Start audio input stream\n",
    "stream.start_stream()\n",
    "\n",
    "# Capture until we have X number of files for testing\n",
    "all_result = []\n",
    "data_int = []\n",
    "prev_result = None\n",
    "thread_path = '../../Data/Thread_files/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start the Real Time System"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def load_file_into_buffer(file_path, file_name, window_size = 0.5):\n",
    "    audio_data = get_audio(file_path, file_name)\n",
    "    (nchannels, sampwidth, framerate, nframes, comptype, compname), sample_wav = audio_data\n",
    "\n",
    "    audio_length = nframes / framerate # length of wav in seconds\n",
    "    # buffer_windows = nframes * len_wav # number of windows we need\n",
    "    load_buffer = deque()\n",
    "\n",
    "    # split audio into chunks of window_size and feed them into the buffer\n",
    "    left = sample_wav[0::nchannels]\n",
    "    # for t_start in range(0, int(len_wav), int(window_size)):\n",
    "\n",
    "    t_start = 0\n",
    "    while True:\n",
    "        if t_start == 0: #first sample\n",
    "            start = t_start\n",
    "            end = t_start + window_size\n",
    "        else:\n",
    "            start = t_start\n",
    "            end = t_start + window_size\n",
    "\n",
    "        if audio_length < end:\n",
    "            end = audio_length\n",
    "\n",
    "        sample_left = left[int(start * framerate):int(end * framerate)]\n",
    "        load_buffer.append(np.array(sample_left).astype('int16'))\n",
    "\n",
    "        if audio_length == end: break\n",
    "        else: t_start = end\n",
    "    return load_buffer\n",
    "\n",
    "def wait_for_file_idx(file_index_, file_idx_, audio_clip_length):\n",
    "    while True:\n",
    "        return_file_name = file_index_.get(file_idx_)\n",
    "        if not return_file_name:\n",
    "            time.sleep(audio_clip_length / 2)\n",
    "            continue\n",
    "        else:\n",
    "            return return_file_name\n",
    "\n",
    "def get_deepspeech_predictions(buffer, deepspeech_model):\n",
    "    # compile list from buffer\n",
    "    data_input = []\n",
    "    for s in buffer:\n",
    "        data_input += list(s)\n",
    "\n",
    "    # down sample audio to 16K\n",
    "    number_of_samples = round(len(data_input) * float(16000) / RATE)\n",
    "    data_16K = sps.resample(data_input, number_of_samples)\n",
    "\n",
    "    # make prediction on audio data\n",
    "    stream_context = deepspeech_model.createStream()\n",
    "    stream_context.feedAudioContent(data_16K.astype('int16')) # feed audio array to model\n",
    "    text = stream_context.finishStream() # text predicted\n",
    "\n",
    "    # get polaraty of audio\n",
    "    tb_result = TextBlob(text)\n",
    "    sentiment = np.array([tb_result.polarity])\n",
    "    #sentiment = np.array([tb_result.polarity, tb_result.subjectivity]).reshape((-1, 1))\n",
    "\n",
    "    return text, sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger deepspeech\n",
      "deepspeech runtime: 10.714773654937744\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 2.439002275466919\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 2.1010115146636963\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 2.4699885845184326\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 13.28990912437439\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 7.9573073387146\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 11.243627309799194\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 4.762020111083984\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 2.021017074584961\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 7.460062265396118\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 3.1319997310638428\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 2.6110074520111084\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 5.623059988021851\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 5.428000450134277\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 3.1059987545013428\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 4.4939985275268555\n",
      "trigger deepspeech\n",
      "deepspeech runtime: 3.6309995651245117\n"
     ]
    }
   ],
   "source": [
    "# Recording flag & file count\n",
    "recording = True\n",
    "file_idx = 0\n",
    "while recording:\n",
    "\n",
    "    # Step 1: Index files\n",
    "    if len(file_index) == 0: # wait for the first file to be written\n",
    "        #print(\"indexing first file\")\n",
    "        file_name = wait_for_file_idx(file_index, 0, file_len)\n",
    "        feeder_buffer = load_file_into_buffer(thread_path, file_name, WINDOW_SIZE)\n",
    "\n",
    "        if multi_modal:\n",
    "            # When we load in a new file, run deepspeech\n",
    "            print(\"trigger deepspeech\"); start_ds_time = time.time()\n",
    "            text, sentiment = get_deepspeech_predictions(feeder_buffer, deepspeech_model_8)\n",
    "            print(\"deepspeech runtime: \" + str(time.time() - start_ds_time))\n",
    "\n",
    "    if len(feeder_buffer) == 0: # if the feeder buffer is empty, read in a new audio file\n",
    "        #print(\"loading to feeder\")\n",
    "        file_idx += 1\n",
    "        file_name = wait_for_file_idx(file_index, file_idx, WINDOW_SIZE)\n",
    "        feeder_buffer = load_file_into_buffer(thread_path, file_name, WINDOW_SIZE)\n",
    "\n",
    "        if multi_modal:\n",
    "            # When we load in a new file, run deepspeech\n",
    "            print(\"trigger deepspeech\"); start_ds_time = time.time()\n",
    "            text, sentiment = get_deepspeech_predictions(feeder_buffer, deepspeech_model_8)\n",
    "            print(\"deepspeech runtime: \" + str(time.time() - start_ds_time))\n",
    "\n",
    "    # Step 2: Move 1 window of the Feeder Buffer into the Process Buffer\n",
    "    process_buffer.append(feeder_buffer.popleft())\n",
    "\n",
    "    data_int = []\n",
    "    for sample in process_buffer:\n",
    "        data_int += list(sample)\n",
    "\n",
    "    data_int = np.array(data_int).astype('int16')\n",
    "\n",
    "    # Step 3: Calculate Features\n",
    "    st_features = calculate_features(data_int, RATE, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    st_features = np.array([st_features.T])\n",
    "\n",
    "    # Step 4: predict on model\n",
    "    with tf.device('/gpu:0'):\n",
    "        if multi_modal:\n",
    "            wav_test_results = model.predict([st_features, sentiment])\n",
    "        else:\n",
    "            wav_test_results = model.predict(st_features)\n",
    "\n",
    "    # Step 5: Graph output\n",
    "    predicted_values = pd.DataFrame({cols[0]:wav_test_results[0][0],\n",
    "                                 cols[1]:wav_test_results[0][1],\n",
    "                                 cols[2]:wav_test_results[0][2],\n",
    "                                 cols[3]:wav_test_results[0][3]\n",
    "    }, index=[1])\n",
    "\n",
    "    # pass previous values to filter function\n",
    "    predicted_values = noise_filter(df_pred_wav.tail(1),\n",
    "                                    predicted_values)\n",
    "\n",
    "    df_pred_wav = df_pred_wav.append(predicted_values,\n",
    "                                     ignore_index=True)\n",
    "\n",
    "    df_pred_wav_view = df_pred_wav.tail(graph_window)\n",
    "    df_pred_wav_view.reset_index(drop=True, inplace=True)\n",
    "    ax[0].cla()\n",
    "    ax[1].cla()\n",
    "\n",
    "    ax[0] = plot_line_graph(ax[0], df_pred_wav_view)\n",
    "\n",
    "    last_res = wav_test_results[0]\n",
    "    ax[1] = plot_bar_graph (ax[1], last_res)\n",
    "\n",
    "    if multi_modal:\n",
    "        ax[2] = plot_text([text], sentiment)\n",
    "\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "\n",
    "    except TclError:\n",
    "\n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        print('stream stopped')\n",
    "\n",
    "    if file_idx > 15:\n",
    "        recording = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "stream.stop_stream()\n",
    "stream.close()\n",
    "wf.close()\n",
    "\n",
    "p.terminate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}